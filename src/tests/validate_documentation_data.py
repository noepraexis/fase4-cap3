#!/usr/bin/env python3
"""
Script para validar que a documenta√ß√£o cont√©m os valores exatos do projeto.
Compara dados da documenta√ß√£o com os resultados reais extra√≠dos.
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import json
import re
from pathlib import Path
from data_loader import load_seeds_data
from config import FEATURE_NAMES

# Constantes
TEST_DATA_DIR = '../../assets/test_data'
DOCS_DIR = '../../docs'
DOC_FILE = 'analise_classificacao_graos.md'

def load_test_data():
    """Carrega dados dos testes para valida√ß√£o."""
    
    test_files = {
        'distributions': 'distributions_data.json',
        'correlations': 'correlation_data.json',
        'boxplots': 'boxplot_data.json',
        'pairplot': 'pairplot_data.json'
    }
    
    loaded_data = {}
    
    for key, filename in test_files.items():
        file_path = os.path.join(TEST_DATA_DIR, filename)
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                loaded_data[key] = json.load(f)
            print(f"‚úÖ Carregado: {filename}")
        except FileNotFoundError:
            print(f"‚ùå Arquivo n√£o encontrado: {file_path}")
            return None
    
    return loaded_data

def read_documentation():
    """L√™ o arquivo de documenta√ß√£o."""
    
    doc_path = os.path.join(DOCS_DIR, DOC_FILE)
    
    try:
        with open(doc_path, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"‚úÖ Documenta√ß√£o carregada: {doc_path}")
        return content
    except FileNotFoundError:
        print(f"‚ùå Documenta√ß√£o n√£o encontrada: {doc_path}")
        return None

def validate_distribution_values(test_data, doc_content):
    """Valida valores das distribui√ß√µes na documenta√ß√£o."""
    
    print("\nüîç VALIDANDO VALORES DAS DISTRIBUI√á√ïES")
    print("=" * 50)
    
    distributions = test_data['distributions']['distributions']
    errors = []
    validations = []
    
    # Validar coeficientes de varia√ß√£o
    cv_values = {}
    for feature in FEATURE_NAMES:
        cv = distributions[feature]['general_stats']['coefficient_variation']
        cv_values[feature] = cv
        
        # Buscar na documenta√ß√£o
        cv_rounded = round(cv, 1)
        
        # Padr√µes de busca espec√≠ficos para cada caracter√≠stica
        search_patterns = {
            'area': r'√°rea.*?(\d+\.?\d*)%',
            'perimeter': r'per√≠metro.*?(\d+\.?\d*)%',
            'compactness': r'compacidade.*?(\d+\.?\d*)%',
            'kernel_length': r'comprimento do n√∫cleo.*?(\d+\.?\d*)%',
            'kernel_width': r'largura do n√∫cleo.*?(\d+\.?\d*)%',
            'asymmetry_coefficient': r'coeficiente de assimetria.*?(\d+\.?\d*)%',
            'kernel_groove_length': r'comprimento do sulco.*?(\d+\.?\d*)%'
        }
        
        pattern = search_patterns.get(feature, f'{feature}.*?(\\d+\\.?\\d*)%')
        matches = re.findall(pattern, doc_content, re.IGNORECASE)
        
        if matches:
            doc_value = float(matches[0])
            if abs(doc_value - cv_rounded) < 0.1:
                validations.append(f"‚úÖ {feature}: CV = {cv_rounded}% (documentado: {doc_value}%)")
            else:
                errors.append(f"‚ùå {feature}: CV real = {cv_rounded}%, documentado = {doc_value}%")
        else:
            errors.append(f"‚ö†Ô∏è {feature}: CV n√£o encontrado na documenta√ß√£o")
    
    # Validar outliers
    total_outliers = 0
    for feature in FEATURE_NAMES:
        outlier_count = distributions[feature]['outliers']['count']
        total_outliers += outlier_count
    
    # Buscar total de outliers na documenta√ß√£o
    outlier_patterns = [
        r'apenas (\d+) valores? at√≠picos?',
        r'(\d+) outliers?',
        r'(\d+) valores? extremos?'
    ]
    
    outlier_found = False
    for pattern in outlier_patterns:
        matches = re.findall(pattern, doc_content, re.IGNORECASE)
        if matches:
            doc_outliers = int(matches[0])
            if doc_outliers == total_outliers:
                validations.append(f"‚úÖ Total outliers: {total_outliers} (documentado: {doc_outliers})")
                outlier_found = True
                break
            else:
                errors.append(f"‚ùå Outliers real = {total_outliers}, documentado = {doc_outliers}")
                outlier_found = True
                break
    
    if not outlier_found:
        errors.append("‚ö†Ô∏è Total de outliers n√£o encontrado na documenta√ß√£o")
    
    # Validar balanceamento (70 amostras por classe)
    samples_per_class = 70
    balance_patterns = [
        r'(\d+) amostras cada',
        r'exatamente (\d+) amostras',
        r'(\d+) amostras por'
    ]
    
    balance_found = False
    for pattern in balance_patterns:
        matches = re.findall(pattern, doc_content)
        if matches:
            doc_balance = int(matches[0])
            if doc_balance == samples_per_class:
                validations.append(f"‚úÖ Amostras por classe: {samples_per_class} (documentado: {doc_balance})")
                balance_found = True
                break
    
    if not balance_found:
        errors.append("‚ö†Ô∏è Balanceamento de classes n√£o encontrado na documenta√ß√£o")
    
    return validations, errors

def validate_correlation_values(test_data, doc_content):
    """Valida valores das correla√ß√µes na documenta√ß√£o."""
    
    print("\nüîç VALIDANDO VALORES DAS CORRELA√á√ïES")
    print("=" * 50)
    
    correlations = test_data['correlations']['categorized']
    errors = []
    validations = []
    
    # Validar n√∫mero de correla√ß√µes por categoria
    categories = {
        'very_strong': len(correlations['very_strong']),
        'strong': len(correlations['strong']),
        'moderate': len(correlations['moderate']),
        'weak': len(correlations['weak'])
    }
    
    # Buscar na documenta√ß√£o
    very_strong_patterns = [
        r'(\d+) correla√ß√µes muito fortes',
        r'Seis correla√ß√µes muito fortes',
        r'(\d+) correla√ß√µes.*?>.*?0\.9'
    ]
    
    for pattern in very_strong_patterns:
        matches = re.findall(pattern, doc_content, re.IGNORECASE)
        if matches:
            try:
                doc_count = int(matches[0]) if matches[0].isdigit() else 6  # "Seis" = 6
                if doc_count == categories['very_strong']:
                    validations.append(f"‚úÖ Correla√ß√µes muito fortes: {categories['very_strong']} (documentado: {doc_count})")
                    break
                else:
                    errors.append(f"‚ùå Correla√ß√µes muito fortes real = {categories['very_strong']}, documentado = {doc_count}")
                    break
            except:
                continue
    
    # Validar correla√ß√µes espec√≠ficas mencionadas
    specific_correlations = [
        ('area', 'perimeter', 0.994),
        ('perimeter', 'kernel_length', 0.972),
        ('area', 'kernel_width', 0.971)
    ]
    
    for feat1, feat2, expected_corr in specific_correlations:
        # Buscar correla√ß√£o espec√≠fica
        patterns = [
            rf'{feat1}.*?{feat2}.*?(\d\.\d{{3}})',
            rf'{feat2}.*?{feat1}.*?(\d\.\d{{3}})',
            rf'correla√ß√£o.*?{feat1}.*?{feat2}.*?(\d\.\d{{3}})',
            rf'r.*?=.*?(\d\.\d{{3}})'
        ]
        
        found = False
        for pattern in patterns:
            matches = re.findall(pattern, doc_content, re.IGNORECASE)
            for match in matches:
                doc_corr = float(match)
                if abs(doc_corr - expected_corr) < 0.001:
                    validations.append(f"‚úÖ Correla√ß√£o {feat1}-{feat2}: {expected_corr} (documentado: {doc_corr})")
                    found = True
                    break
            if found:
                break
    
    return validations, errors

def validate_boxplot_values(test_data, doc_content):
    """Valida valores dos boxplots na documenta√ß√£o."""
    
    print("\nüîç VALIDANDO VALORES DOS BOXPLOTS")
    print("=" * 50)
    
    boxplots = test_data['boxplots']['boxplot_data']['discrimination_ranking']
    errors = []
    validations = []
    
    # Validar ratios discriminativos
    expected_ratios = dict(boxplots)
    
    # Buscar ratios na documenta√ß√£o
    ratio_patterns = [
        r'√°rea.*?ratio.*?(\d\.\d{2})',
        r'per√≠metro.*?(\d\.\d{2})',
        r'largura.*?n√∫cleo.*?(\d\.\d{2})',
        r'comprimento.*?n√∫cleo.*?(\d\.\d{2})',
        r'discrimination.*?ratio.*?(\d\.\d{2})'
    ]
    
    # Validar o primeiro lugar (√°rea com 4.84)
    area_ratio = expected_ratios['area']
    if f"{area_ratio:.2f}" in doc_content:
        validations.append(f"‚úÖ √Årea discrimination ratio: {area_ratio:.2f}")
    else:
        errors.append(f"‚ùå √Årea discrimination ratio {area_ratio:.2f} n√£o encontrado")
    
    # Validar ranking top 3
    top_3_features = [boxplots[i][0] for i in range(3)]
    ranking_text = ["√°rea", "per√≠metro", "largura do n√∫cleo"]
    
    ranking_found = all(feat in doc_content.lower() for feat in ranking_text)
    if ranking_found:
        validations.append("‚úÖ Ranking top 3 caracter√≠sticas discriminativas encontrado")
    else:
        errors.append("‚ùå Ranking top 3 caracter√≠sticas n√£o encontrado")
    
    return validations, errors

def validate_pairplot_values(test_data, doc_content):
    """Valida valores do pairplot na documenta√ß√£o."""
    
    print("\nüîç VALIDANDO VALORES DO PAIRPLOT")
    print("=" * 50)
    
    pairplot = test_data['pairplot']['pairplot_data']
    errors = []
    validations = []
    
    # Validar √≠ndice Calinski-Harabasz
    expected_ch = pairplot['quality_metrics']['calinski_harabasz_index']
    
    ch_patterns = [
        r'Calinski-Harabasz.*?(\d{3}\.\d{2})',
        r'√≠ndice.*?(\d{3}\.\d{2})',
        r'CH.*?(\d{3}\.\d{2})'
    ]
    
    ch_found = False
    for pattern in ch_patterns:
        matches = re.findall(pattern, doc_content, re.IGNORECASE)
        if matches:
            doc_ch = float(matches[0])
            if abs(doc_ch - expected_ch) < 0.1:
                validations.append(f"‚úÖ √çndice Calinski-Harabasz: {expected_ch:.2f} (documentado: {doc_ch})")
                ch_found = True
                break
    
    if not ch_found:
        if f"{expected_ch:.2f}" in doc_content:
            validations.append(f"‚úÖ √çndice Calinski-Harabasz: {expected_ch:.2f} encontrado")
        else:
            errors.append(f"‚ùå √çndice Calinski-Harabasz {expected_ch:.2f} n√£o encontrado")
    
    # Validar qualidade "EXCELENTE"
    if "EXCELENTE" in doc_content:
        validations.append("‚úÖ Qualidade 'EXCELENTE' mencionada")
    else:
        errors.append("‚ùå Qualidade 'EXCELENTE' n√£o encontrada")
    
    # Validar n√∫mero de caracter√≠sticas no pairplot
    expected_features = len(pairplot['features'])
    if f"{expected_features} caracter√≠sticas" in doc_content or "quatro caracter√≠sticas" in doc_content:
        validations.append(f"‚úÖ N√∫mero de caracter√≠sticas no pairplot: {expected_features}")
    else:
        errors.append(f"‚ùå N√∫mero de caracter√≠sticas no pairplot ({expected_features}) n√£o encontrado")
    
    return validations, errors

def main():
    """Fun√ß√£o principal para validar a documenta√ß√£o."""
    
    print("üîç INICIANDO VALIDA√á√ÉO DA DOCUMENTA√á√ÉO")
    print("=" * 60)
    
    # Carregar dados de teste
    test_data = load_test_data()
    if not test_data:
        print("‚ùå Falha ao carregar dados de teste")
        return
    
    # Carregar documenta√ß√£o
    doc_content = read_documentation()
    if not doc_content:
        print("‚ùå Falha ao carregar documenta√ß√£o")
        return
    
    # Realizar valida√ß√µes
    all_validations = []
    all_errors = []
    
    # Validar cada se√ß√£o
    validations, errors = validate_distribution_values(test_data, doc_content)
    all_validations.extend(validations)
    all_errors.extend(errors)
    
    validations, errors = validate_correlation_values(test_data, doc_content)
    all_validations.extend(validations)
    all_errors.extend(errors)
    
    validations, errors = validate_boxplot_values(test_data, doc_content)
    all_validations.extend(validations)
    all_errors.extend(errors)
    
    validations, errors = validate_pairplot_values(test_data, doc_content)
    all_validations.extend(validations)
    all_errors.extend(errors)
    
    # Relat√≥rio final
    print("\n" + "=" * 60)
    print("RELAT√ìRIO DE VALIDA√á√ÉO")
    print("=" * 60)
    
    print(f"\n‚úÖ VALIDA√á√ïES APROVADAS ({len(all_validations)}):")
    for validation in all_validations:
        print(f"  {validation}")
    
    if all_errors:
        print(f"\n‚ùå ERROS ENCONTRADOS ({len(all_errors)}):")
        for error in all_errors:
            print(f"  {error}")
    
    # Score de qualidade
    total_checks = len(all_validations) + len(all_errors)
    if total_checks > 0:
        quality_score = (len(all_validations) / total_checks) * 100
        print(f"\nüìä PONTUA√á√ÉO DE QUALIDADE: {quality_score:.1f}%")
        
        if quality_score >= 95:
            print("üåü QUALIDADE: EXCELENTE")
        elif quality_score >= 85:
            print("‚≠ê QUALIDADE: MUITO BOA")
        elif quality_score >= 70:
            print("‚úÖ QUALIDADE: BOA")
        else:
            print("‚ö†Ô∏è QUALIDADE: PRECISA MELHORAR")
    
    print(f"\n{'='*60}")
    if len(all_errors) == 0:
        print("üéâ DOCUMENTA√á√ÉO VALIDADA COM SUCESSO!")
        print("Todos os valores est√£o consistentes com os dados reais.")
    else:
        print("‚ö†Ô∏è DOCUMENTA√á√ÉO REQUER CORRE√á√ïES")
        print("Alguns valores n√£o est√£o consistentes com os dados reais.")
    
    return len(all_errors) == 0

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
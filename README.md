# Da Terra ao CÃ³digo: Automatizando a ClassificaÃ§Ã£o de GrÃ£os com Machine Learning

<p align="center">
    <a href="https://www.fiap.com.br/">
        <img src="assets/logo-fiap.png"
             alt="FIAP - Faculdade de InformÃ¡tica e AdministraÃ§Ã£o Paulista"
             border="0" width=40% height=40%>
    </a>
</p>

<br>

## ğŸŒ¾ Sistema Schierke: ClassificaÃ§Ã£o Automatizada de Variedades de Trigo

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0%2B-orange)](https://scikit-learn.org)
[![License](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey)](http://creativecommons.org/licenses/by/4.0/)
[![FIAP](https://img.shields.io/badge/FIAP-Fase%204%20Cap%203-red)](https://fiap.com.br)

## ğŸ‘¨â€ğŸ“ InformaÃ§Ãµes do Grupo: NOEPRÃ†XIS
|Nome Completo|RM|ContribuiÃ§Ã£o Principal|
|---|---|---|
|[ANA CAROLINA BELCHIOR](https://www.linkedin.com/in/ana-carolina-belchior-35a572355/)|RM565875|AnÃ¡lise ExploratÃ³ria e VisualizaÃ§Ãµes|
|[CAIO PELLEGRINI](https://www.linkedin.com/in/caiopellegrini/)|RM566575|Modelagem de Machine Learning|
|[LEONARDO DE SENA](https://www.linkedin.com/in/leonardosena)|RM563351|Arquitetura de Software e Deployment|
|[VIVIAN NASCIMENTO SILVA AMORIM](https://www.linkedin.com/in/vivian-amorim-245a46b7)|RM565078|DocumentaÃ§Ã£o TÃ©cnica e Metodologia|

## ğŸ‘©â€ğŸ« OrientaÃ§Ã£o AcadÃªmica
### Tutor
- [Leonardo Ruiz Orabona](https://www.linkedin.com/in/leonardoorabona)
### Coordenador
- [AndrÃ© Godoi Chiovato](https://www.linkedin.com/in/andregodoichiovato)

## ğŸ“œ VisÃ£o Geral

### ğŸ¯ Problema de NegÃ³cio

Cooperativas agrÃ­colas de pequeno porte enfrentam desafios significativos na classificaÃ§Ã£o manual de grÃ£os:
- **Throughput limitado**: 12.2 amostras/hora por operador especializado
- **Variabilidade inter-operador**: CV = 14.7% Â± 3.2% em classificaÃ§Ãµes repetidas
- **Custos elevados**: R$ 3.26 por amostra analisada
- **DegradaÃ§Ã£o de performance**: 23% maior erro apÃ³s 4h de trabalho contÃ­nuo

### ğŸ­ Setor de AtuaÃ§Ã£o

**Agricultura de PrecisÃ£o 2.0** - AutomaÃ§Ã£o de processos de classificaÃ§Ã£o e controle de qualidade em cooperativas agrÃ­colas, com foco em:
- ClassificaÃ§Ã£o automatizada de variedades de trigo
- Controle de qualidade baseado em caracterÃ­sticas morfomÃ©tricas
- OtimizaÃ§Ã£o de processos agroindustriais
- ReduÃ§Ã£o de custos operacionais

### ğŸ’¡ SoluÃ§Ã£o Proposta

**Sistema Schierke**: Plataforma de Machine Learning para classificaÃ§Ã£o automatizada de grÃ£os de trigo baseada em caracterÃ­sticas fÃ­sicas, utilizando:
- **Metodologia CRISP-DM** para desenvolvimento estruturado
- **5 algoritmos de classificaÃ§Ã£o** com otimizaÃ§Ã£o de hiperparÃ¢metros
- **Pipeline automatizado** end-to-end
- **AnÃ¡lise quantitativa robusta** com validaÃ§Ã£o estatÃ­stica

## ğŸš€ Resultados AlcanÃ§ados

### ğŸ“Š Performance dos Modelos
- **Melhor acurÃ¡cia**: 88.89% (KNN e SVM otimizados)
- **ValidaÃ§Ã£o cruzada**: 94.60% Â± 3.41% (KNN), 97.31% Â± 2.50% (SVM)
- **Separabilidade**: Calinski-Harabasz = 540.54 (excepcional)
- **Poder discriminativo**: Fisher Ratio = 548.19 para Ã¡rea

### ğŸ’° Impacto EconÃ´mico
- **Throughput automatizado**: 900 amostras/hora (vs. 12.2 manual)
- **ReduÃ§Ã£o de custos**: 92.3% por amostra
- **ROI projetado**: 8% ao ano com payback de 11 meses
- **EficiÃªncia**: 73x aumento de produtividade

## ğŸ“‹ Desenvolvimento do Projeto

### ğŸ¯ Objetivos

1. **TÃ©cnicos**:
   - Desenvolver modelo ML com acurÃ¡cia >85% para viabilidade comercial
   - Implementar pipeline automatizado end-to-end
   - Validar robustez estatÃ­stica via cross-validation
   - Projetar arquitetura para deployment industrial

2. **CientÃ­ficos**:
   - Aplicar metodologia CRISP-DM rigorosamente
   - Comparar 5 algoritmos de classificaÃ§Ã£o diferentes
   - Otimizar hiperparÃ¢metros via Grid Search
   - Extrair insights sobre caracterÃ­sticas discriminativas

3. **PrÃ¡ticos**:
   - Automatizar processo manual de classificaÃ§Ã£o
   - Reduzir custos operacionais significativamente
   - Aumentar throughput e consistÃªncia
   - Estabelecer base para expansÃ£o tecnolÃ³gica

### ğŸ“ Estrutura de DiretÃ³rios

```
projeto/
â”œâ”€â”€ ğŸ“„ README.md                    # DocumentaÃ§Ã£o principal
â”œâ”€â”€ ğŸ“„ requirements.txt             # DependÃªncias Python
â”œâ”€â”€ ğŸ“„ CLAUDE.md                    # InstruÃ§Ãµes de desenvolvimento
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“‚ .private/                    # ConfiguraÃ§Ãµes privadas
â”‚   â””â”€â”€ claude/fiap.md             # EspecificaÃ§Ãµes da atividade
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“‚ datasets/                    # Dados do projeto
â”‚   â”œâ”€â”€ ğŸ“„ README.md               # DocumentaÃ§Ã£o dos dados
â”‚   â”œâ”€â”€ ğŸ“„ seeds_dataset.txt       # Seeds Dataset (210 amostras)
â”‚   â””â”€â”€ ğŸ“„ seeds.zip               # Backup compactado
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“‚ src/                         # CÃ³digo fonte
â”‚   â”œâ”€â”€ ğŸ config.py               # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ ğŸ main.py                 # Pipeline principal
â”‚   â”œâ”€â”€ ğŸ data_loader.py          # Carregamento de dados
â”‚   â”œâ”€â”€ ğŸ eda.py                  # AnÃ¡lise exploratÃ³ria
â”‚   â”œâ”€â”€ ğŸ preprocessing.py        # PrÃ©-processamento
â”‚   â”œâ”€â”€ ğŸ models.py               # Modelagem ML
â”‚   â”œâ”€â”€ ğŸ visualization.py        # VisualizaÃ§Ãµes
â”‚   â”œâ”€â”€ ğŸ utils.py                # UtilitÃ¡rios
â”‚   â””â”€â”€ ğŸ“‚ tests/                  # Scripts de validaÃ§Ã£o
â”‚       â”œâ”€â”€ ğŸ analyze_*.py        # AnÃ¡lises especÃ­ficas
â”‚       â””â”€â”€ ğŸ calculate_*.py      # CÃ¡lculos matemÃ¡ticos
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“‚ models/                      # Modelos treinados
â”‚   â”œâ”€â”€ ğŸ“¦ best_model_knn.pkl      # Melhor modelo (KNN)
â”‚   â”œâ”€â”€ ğŸ“¦ scaler.pkl              # Normalizador
â”‚   â””â”€â”€ ğŸ“„ model_info.json         # Metadados
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“‚ assets/                      # VisualizaÃ§Ãµes
â”‚   â”œâ”€â”€ ğŸ–¼ï¸ logo-fiap.png           # Logo institucional
â”‚   â”œâ”€â”€ ğŸ“Š distributions.png       # DistribuiÃ§Ãµes
â”‚   â”œâ”€â”€ ğŸ“Š correlation_matrix.png  # Matriz de correlaÃ§Ã£o
â”‚   â”œâ”€â”€ ğŸ“Š model_comparison.png    # ComparaÃ§Ã£o de modelos
â”‚   â””â”€â”€ ğŸ“Š *.png                   # Demais visualizaÃ§Ãµes
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“‚ docs/                        # DocumentaÃ§Ã£o tÃ©cnica
â”‚   â”œâ”€â”€ ğŸ“„ analise_classificacao_graos.md    # AnÃ¡lise principal
â”‚   â”œâ”€â”€ ğŸ“„ guia_algoritmos_ml.md             # Guia de algoritmos
â”‚   â”œâ”€â”€ ğŸ“„ metodologia_crisp_dm.md           # Metodologia
â”‚   â””â”€â”€ ğŸ“„ prepare-environment.md            # Setup do ambiente
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“‚ notebooks/                   # Jupyter Notebooks
â”‚   â””â”€â”€ ğŸ““ classificacao_graos_machine_learning.ipynb
â””â”€â”€ 
â””â”€â”€ ğŸ“‚ results/                     # Resultados das execuÃ§Ãµes
    â””â”€â”€ ğŸ“„ analysis_summary_*.txt   # RelatÃ³rios de execuÃ§Ã£o
```

### ğŸ— Arquitetura do Sistema

#### PadrÃ£o Arquitetural

O Sistema Schierke segue **arquitetura modular** com separaÃ§Ã£o clara de responsabilidades:

```mermaid
graph TB
    subgraph "ğŸ“Š Camada de Dados"
        A[datasets/seeds_dataset.txt]
        B[data_loader.py]
    end
    
    subgraph "ğŸ”§ Camada de Processamento"
        C[preprocessing.py]
        D[eda.py]
    end
    
    subgraph "ğŸ¤– Camada de Modelagem"
        E[models.py]
        F[Grid Search]
        G[Cross Validation]
    end
    
    subgraph "ğŸ“ˆ Camada de VisualizaÃ§Ã£o"
        H[visualization.py]
        I[assets/*.png]
    end
    
    subgraph "ğŸ’¾ Camada de PersistÃªncia"
        J[models/*.pkl]
        K[results/*.txt]
    end
    
    A --> B
    B --> C
    B --> D
    C --> E
    E --> F
    F --> G
    G --> J
    D --> H
    H --> I
    E --> K
```

### ğŸ’» Como Executar o Projeto

#### ğŸ”§ PrÃ©-requisitos

**Sistema Operacional**: Linux, Windows ou macOS  
**Python**: 3.8 ou superior  
**MemÃ³ria RAM**: MÃ­nimo 4GB (recomendado 8GB)  
**EspaÃ§o em disco**: 500MB livres  

**DependÃªncias principais:**
```bash
pandas>=1.3.0       # ManipulaÃ§Ã£o de dados
numpy>=1.21.0       # ComputaÃ§Ã£o numÃ©rica
scikit-learn>=1.0.0 # Machine Learning
matplotlib>=3.5.0   # VisualizaÃ§Ã£o
seaborn>=0.11.0     # VisualizaÃ§Ã£o estatÃ­stica
jupyter>=1.0.0      # Notebooks interativos
joblib>=1.1.0       # PersistÃªncia de modelos
```

#### ğŸ“¥ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**:
```bash
git clone https://github.com/noepraexis/fase4-cap3.git
cd fase4-cap3
```

2. **Instale as dependÃªncias**:
```bash
# DependÃªncias principais
pip install -r requirements.txt

# DependÃªncias de desenvolvimento (opcional)
pip install -r requirements.dev.txt
```

3. **Verifique a instalaÃ§Ã£o**:
```bash
python -c "import pandas, numpy, sklearn; print('âœ… DependÃªncias instaladas com sucesso')"
```

#### â–¶ï¸ ExecuÃ§Ã£o

##### OpÃ§Ã£o 1: Pipeline Completo (Recomendado)
```bash
# Execute o pipeline completo de ML
python src/main.py
```

**SaÃ­da esperada:**
```
ğŸŒ¾ SISTEMA SCHIERKE v1.0.0 - ClassificaÃ§Ã£o de GrÃ£os
================================================================================
ğŸ“Š Carregando dados...
   âœ… Dataset carregado: 210 amostras, 7 caracterÃ­sticas
   âœ… Qualidade dos dados: 100/100 (sem missing values)

ğŸ” AnÃ¡lise ExploratÃ³ria...
   âœ… DistribuiÃ§Ãµes: assets/distributions.png
   âœ… CorrelaÃ§Ãµes: assets/correlation_matrix.png
   âœ… Pairplot: assets/pairplot.png

ğŸ› ï¸ PrÃ©-processamento...
   âœ… DivisÃ£o treino/teste: 70/30 estratificada
   âœ… NormalizaÃ§Ã£o aplicada: StandardScaler

ğŸ¤– Treinamento de modelos...
   âœ… KNN: 88.89% acurÃ¡cia
   âœ… SVM: 88.89% acurÃ¡cia
   âœ… Random Forest: 87.30% acurÃ¡cia
   âœ… Naive Bayes: 82.54% acurÃ¡cia
   âœ… Logistic Regression: 85.71% acurÃ¡cia

ğŸ”§ OtimizaÃ§Ã£o (Grid Search)...
   âœ… KNN otimizado: 88.89% â†’ 88.89% (mantido)
   âœ… SVM otimizado: 88.89% â†’ 88.89% (mantido)
   âœ… Random Forest otimizado: 87.30% â†’ 87.30% (mantido)

âœ… ValidaÃ§Ã£o cruzada...
   âœ… KNN: 94.60% Â± 3.41%
   âœ… SVM: 97.31% Â± 2.50%

ğŸ’¾ Salvando modelo...
   âœ… Melhor modelo: models/best_model_knn.pkl
   âœ… Scaler: models/scaler.pkl

ğŸ¯ RESULTADOS FINAIS:
   â€¢ Melhor acurÃ¡cia: 88.89% (KNN e SVM)
   â€¢ Melhor validaÃ§Ã£o cruzada: 97.31% Â± 2.50% (SVM)
   â€¢ CaracterÃ­sticas mais importantes: Ã¡rea, perÃ­metro
   â€¢ Tempo total de execuÃ§Ã£o: ~3 minutos
```

##### OpÃ§Ã£o 2: Notebook Interativo
```bash
# Inicie o Jupyter Notebook
jupyter notebook

# Abra o arquivo:
# notebooks/classificacao_graos_machine_learning.ipynb
```

##### OpÃ§Ã£o 3: MÃ³dulos Individuais
```bash
# Apenas anÃ¡lise exploratÃ³ria
python -c "
import sys; sys.path.append('src')
from data_loader import load_seeds_data
from eda import run_eda
data = load_seeds_data()
run_eda(data)
"

# Apenas treinamento
python -c "
import sys; sys.path.append('src')
from main import run_modeling_pipeline
run_modeling_pipeline()
"
```

### ğŸ“Š Dados e Metodologia

#### Dataset: Seeds Dataset (UCI)

**Fonte**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/236/seeds)  
**Autores**: Charytanowicz et al. (2010)  
**TÃ©cnica de mediÃ§Ã£o**: Soft X-ray (nÃ£o-destrutiva)

| CaracterÃ­stica | Unidade | Faixa | DescriÃ§Ã£o |
|---|---|---|---|
| `area` | mmÂ² | 10.59-21.18 | Ãrea superficial do grÃ£o |
| `perimeter` | mm | 12.41-17.25 | PerÃ­metro do contorno |
| `compactness` | - | 0.808-0.918 | Compacidade (4Ï€Ã—Ã¡rea/perÃ­metroÂ²) |
| `kernel_length` | mm | 4.899-6.675 | Comprimento do nÃºcleo |
| `kernel_width` | mm | 2.630-4.033 | Largura do nÃºcleo |
| `asymmetry_coefficient` | - | 0.765-8.456 | Coeficiente de assimetria |
| `kernel_groove_length` | mm | 4.519-6.550 | Comprimento do sulco |

**Classes**: 3 variedades de trigo
- **Kama** (Classe 1): 70 amostras
- **Rosa** (Classe 2): 70 amostras  
- **Canadian** (Classe 3): 70 amostras

### ğŸ“ˆ Resultados e VisualizaÃ§Ãµes

O sistema gera **9 visualizaÃ§Ãµes** diferentes para anÃ¡lise completa:

#### ğŸ“Š AnÃ¡lise ExploratÃ³ria
1. **`distributions.png`**: Histogramas das 7 caracterÃ­sticas + distribuiÃ§Ã£o das classes
2. **`boxplots_by_variety.png`**: Boxplots comparativos por variedade
3. **`correlation_matrix.png`**: Matriz de correlaÃ§Ã£o das caracterÃ­sticas
4. **`pairplot.png`**: Scatter plots pareados coloridos por variedade

#### ğŸ¤– Resultados de Modelagem
5. **`model_comparison.png`**: ComparaÃ§Ã£o de acurÃ¡cia dos 5 algoritmos
6. **`confusion_matrices.png`**: Matrizes de confusÃ£o dos modelos
7. **`cross_validation_results.png`**: Resultados da validaÃ§Ã£o cruzada
8. **`feature_importance.png`**: ImportÃ¢ncia das caracterÃ­sticas (Random Forest)
9. **`optimization_comparison.png`**: ComparaÃ§Ã£o antes/depois da otimizaÃ§Ã£o

### ğŸ“š DocumentaÃ§Ã£o TÃ©cnica Completa

Para anÃ¡lise detalhada, consulte:

- **[AnÃ¡lise TÃ©cnica Completa](docs/analise_classificacao_graos.md)**: AnÃ¡lise cientÃ­fica detalhada com fundamentaÃ§Ã£o teÃ³rica
- **[Guia de Algoritmos](docs/guia_algoritmos_ml.md)**: DocumentaÃ§Ã£o tÃ©cnica de cada algoritmo implementado
- **[Metodologia CRISP-DM](docs/metodologia_crisp_dm.md)**: AplicaÃ§Ã£o da metodologia de Data Mining
- **[PreparaÃ§Ã£o do Ambiente](docs/prepare-environment.md)**: Guia detalhado de configuraÃ§Ã£o

### ğŸ¯ AplicaÃ§Ã£o Industrial

**CenÃ¡rio de ImplementaÃ§Ã£o:**
- Cooperativas agrÃ­colas com 50.000 amostras/ano
- ReduÃ§Ã£o de custos de 92.3% por amostra
- Aumento de throughput de 73x
- ROI de 8% ao ano com payback de 11 meses

### ğŸ” ValidaÃ§Ã£o de Dados

Execute o script de validaÃ§Ã£o para verificar a consistÃªncia dos dados:

```bash
python scripts/validate_data.py
```

**SaÃ­da esperada:**
```
============================================================
ğŸ” VALIDAÃ‡ÃƒO DE INTEGRIDADE DOS DADOS
============================================================
âœ… Dataset carregado com sucesso

ğŸ“Š INFORMAÃ‡Ã•ES BÃSICAS:
   â€¢ Amostras: 210
   â€¢ CaracterÃ­sticas: 7
   â€¢ Classes: 3
   â€¢ Missing values: 0
   â€¢ Duplicatas: 0

ğŸ¯ DISTRIBUIÃ‡ÃƒO DAS CLASSES:
   â€¢ Kama (Classe 1): 70 amostras
   â€¢ Rosa (Classe 2): 70 amostras
   â€¢ Canadian (Classe 3): 70 amostras

ğŸ“ˆ COEFICIENTES DE VARIAÃ‡ÃƒO:
   â€¢ area: 19.6%
   â€¢ perimeter: 9.0%
   â€¢ compactness: 2.7%
   â€¢ kernel_length: 7.9%
   â€¢ kernel_width: 11.6%
   â€¢ asymmetry_coefficient: 40.6%
   â€¢ kernel_groove_length: 9.1%

ğŸ”— CORRELAÃ‡Ã•ES PRINCIPAIS:
   â€¢ area Ã— perimeter: 0.994
   â€¢ area Ã— kernel_length: 0.950
   â€¢ area Ã— kernel_width: 0.971

ğŸŒ¾ ESTATÃSTICAS POR VARIEDADE (ÃREA):
   â€¢ Kama: Î¼=14.334, Ïƒ=1.216
   â€¢ Rosa: Î¼=18.334, Ïƒ=1.439
   â€¢ Canadian: Î¼=11.874, Ïƒ=0.723
```

### ğŸ“š ReferÃªncias CientÃ­ficas

- **Charytanowicz, M.** et al. (2010). Complete gradient clustering algorithm for features analysis of X-ray images. *Information Technologies in Biomedicine*, 15-24.
- **Wickens, C.D.** et al. (2004). Introduction to Human Factors Engineering. *Pearson Prentice Hall*.
- **Cohen, J.** (1988). Statistical Power Analysis for the Behavioral Sciences. *Lawrence Erlbaum Associates*.
- **Hair, J.F.** et al. (2019). Multivariate Data Analysis. *Pearson*.

### ğŸ”§ Troubleshooting

#### Problemas Comuns

**1. Erro de importaÃ§Ã£o de mÃ³dulos**
```bash
# SoluÃ§Ã£o: Adicionar src/ ao PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:./src"
```

**2. DependÃªncias nÃ£o encontradas**
```bash
# SoluÃ§Ã£o: Reinstalar dependÃªncias
pip install --upgrade -r requirements.txt
```

**3. Dataset nÃ£o encontrado**
```bash
# SoluÃ§Ã£o: Verificar estrutura de diretÃ³rios
ls -la datasets/seeds_dataset.txt
```

**4. Jupyter Notebook nÃ£o inicia**
```bash
# SoluÃ§Ã£o: Instalar Jupyter
pip install jupyter
jupyter notebook
```

### ğŸ“„ LicenÃ§a

[![LicenÃ§a CC](https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1)](http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1)
[![AtribuiÃ§Ã£o BY](https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1)](http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1)

Este projeto estÃ¡ licenciado sob [Creative Commons AtribuiÃ§Ã£o 4.0 Internacional](http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1).
